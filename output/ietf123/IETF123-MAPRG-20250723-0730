# maprg

## Summary

This MapRG session focused on the increasing issue of crawler traffic, particularly concerning AI crawlers, and its impact on website infrastructure and content access. Presentations covered measurements of crawler behavior, the effectiveness of blocking mechanisms, the experiences of infrastructure operators like the IETF and Wikimedia, and forward-looking approaches like IndexNow for more efficient crawling. The discussion highlighted the need for better standards, cooperation between crawlers and content providers, and sustainable models for knowledge sharing.

## Key Discussion Points

*   **Crawler Traffic Volume and Impact:** Automated traffic accounts for a large share of web traffic (30-50%) with AI crawlers being a major driver. This traffic is increasingly impacting website infrastructure and user experience, especially for high-interest events. Wikimedia noted a 50% increase in bandwidth usage since January 2024 largely due to bots.
*   **Blocking Mechanisms and Their Limitations:** Robots.txt and active blocking are used by content creators to control crawler access, but both have limitations. Robots.txt is voluntary and easily circumvented, while active blocking can impact legitimate users. Cloudflare's AI crawler blocking feature relies on user agent strings, which can be spoofed.
*   **Misuse of HTTP Status Codes:** Websites often misuse HTTP status codes to signal crawler refusals, making it difficult for crawlers to interpret and react appropriately.
*   **Crawler Respect for Robots.txt:**  Most well-known crawlers respect robots.txt, but exceptions exist, particularly among third-party AI assistant crawlers.
*   **Centralization and Its Impact:** Large hosting providers enforcing unified blocking policies can create blind spots for crawlers, affecting a large number of domains.
*   **IndexNow Protocol:**  IndexNow, a protocol for real-time push notifications of content updates, aims to reduce redundant crawling and improve content freshness. 50% of newly indexed URLs on Bing originate from IndexNow.
*   **The Dichotomy of Open Access and Sustainability:**  Maintaining open access to content while ensuring sustainable infrastructure is a key challenge for organizations like Wikimedia.
*   **Need for Sustainable Knowledge-as-a-Service Model:** The meeting discussed the need for systemic, dynamic approaches to maintain preferential access for humans and mission-oriented traffic, while managing the impact of bots.

## Decisions and Action Items

*   **Follow-up on IndexNow:** Encourage more discussion about IndexNow and its potential for wider adoption and standardization within the community.
*   **Continue discussions:** Participants agreed to continue discussions about crawler behavior, blocking effectiveness, and alternative solutions for content access and sustainability.

## Next Steps

*   Further explore standardization efforts for crawler identification and communication of crawling preferences.
*   Investigate best practices for content providers to manage crawler traffic and protect their infrastructure.
*   Promote collaboration between crawlers and content providers to develop sustainable models for knowledge sharing and content reuse.
