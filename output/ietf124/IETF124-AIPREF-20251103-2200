# AIPREF

## Summary

The AIPREF Working Group met to discuss the current status of its drafts after a failed Working Group Last Call and significant new contributions. Milestones have been extended to August 2026, reflecting the need for substantial further work. The primary goal of this meeting was to gather preliminary feedback on newly proposed definitions for core vocabulary terms – "Foundation Model Production," "Search," and "AI Output" – which are still in flux and attempt to reflect discussions from the previous Zurich meeting. No final decisions were made in this session, with the understanding that this is the beginning of a longer discussion to find a fruitful direction.

## Key Discussion Points

*   **Working Group Status Update:**
    *   The previous Working Group Last Call failed due to strong disagreements and new perspectives. The group is effectively "back to square one."
    *   Milestones have been updated to August 2026 to acknowledge the uncertainty and amount of work ahead.
    *   New draft proposals attempt to incorporate previous discussions, particularly from Zurich, but are tentative and require extensive feedback.
    *   The meeting's purpose was to gather preliminary feedback on the new terms, not to make definitive decisions.

*   **Editor's Overview of Draft Changes (Martin Thomson):**
    *   The previous concept of "search" was found problematic due to the extensive use of AI, including model training, by search providers.
    *   The diagram now features "Foundation Model Production" (replacing "AI Training" and "Generative AI Training"), and new categories "AI Output" and "Search."
    *   **Top-level Category**: Remains contested. Some argue for its necessity to control unknown uses, while others fear unintended consequences of such broad scope.
    *   **Foundation Model Production**: Focuses on the *output* (a foundation model) rather than internal processes, aiming for a better-defined category to avoid prior contention over where "AI training" begins (e.g., distinguishing from simple statistical methods).
    *   **AI Output**: Intends to focus on the observable results of systems using AI internally, addressing "substitutive" concerns.
    *   **"Exact Text Match" (formerly "Laterhosen")**: Defined as an output category requiring verbatim excerpts and links to the original source. The name and nesting are acknowledged as problematic.
    *   **Identified Problems with Draft Definitions**:
        *   **Foundation Model Production**: Ambiguity around "fine-tuning" (e.g., does it include prompt engineering or only weight changes?) needs clarification.
        *   **AI Output**: Unclear what "output" means; "presented to a human" vs. "leaves domain of control"? How to decouple output from complex internal AI processes? Testability of preferences is a challenge.
        *   **"Exact Text Match" / "Search"**: Naming and nesting (as a sub-category of AI Output) are sources of confusion.

*   **Discussion on "Foundation Model Production"**:
    *   **Clarity on terms**: Roberta asked for clarification on "foundation" vs. "foundational models" and the historical inclusion of "search" (as an example of an application that relies on AI training and needed to be explicitly permitted).
    *   **Fine-tuning vs. broad model creation**: Brad Gaynor highlighted that "fine-tuning" is a critical aspect for content creators seeking specific controls, suggesting it may warrant separate consideration from the broader creation of a foundation model.
    *   **Scope and Use Cases**: Alyssa questioned if "AI model production" + "AI output" would cover all AI system activities. There was a strong call for developing a set of common *use cases* to test the definitions against, and to leverage existing widely-agreed definitions where possible.
    *   **User Perspective**: Ted Hardy urged focusing on *why* individuals want to express preferences, proposing simpler, user-understandable categories like "citations," "direct answers," or "interactive/generative," rather than technical implementation details.
    *   **Dimensional Approach**: Erick L. Nygren suggested a dimensional approach (e.g., data aggregation, intermixing, preservation) to describe data use, rather than a strict taxonomy.
    *   **Self-Categorization**: Nick Doty emphasized that AI crawlers need to be able to reliably self-categorize their activities based on these definitions.
    *   **Declarant Clarity**: Fars Al-Shareef emphasized clarifying who the "declarant" is (e.g., WordPress for hosted sites) and the need for transparency when preferences are declared on behalf of others.
    *   **IP Status**: Timit Robot cautioned against tying AI preferences to intellectual property status, as it could reduce efficacy and duplicate existing legal frameworks.

*   **Discussion on "Search"**:
    *   **Nesting**: There was widespread consensus that "Search" should *not* be a nested sub-category of "AI Output" due to conceptual and practical issues (e.g., different intents – "yes" for search vs. "no" for other outputs).
    *   **User Understanding**: Meredith Jacob argued that "search" is a term users understand, but that users ultimately care about the *purpose* of AI use (e.g., substitutive vs. assistive), not the specific tools. This raises the challenge of distinguishing between creating competing works and pro-social uses (e.g., accessibility, translation). Martin acknowledged that open-weight models make this distinction difficult for content originators.
    *   **Term Validity**: Mea Cleveland-Erickson suggested avoiding "search" as a term altogether, due to its continuously evolving nature and the mismatch between user expectations and actual implementation. Instead, focus on specific features like "reference and link back."
    *   **Broader Category**: Mallory Nodal suggested "derivative work" as a broader category that could encompass search and other forms of content transformation.
    *   **Verbatim Excerpts**: Brad Gaynor expressed concern that "verbatim excerpts" could still enable substitutive use and that linking training to output categories dilutes informed preference.
    *   **Alternative Granularity**: Alyssa pointed to Krishna's draft for more granular concepts (e.g., indexing, retrieval, display length, image/video aspects) that could be incorporated.
    *   **Creator Intent**: Nate Haig, a small travel blogger, found the current "search" definition (with verbatim excerpts and links) understandable and valuable for ensuring "fair exchange" by driving traffic back. Fars Al-Shareef highlighted that some site operators *want* to be included in all forms of search.

*   **Discussion on "AI Output"**:
    *   **Internal vs. External**: Aaron Simon argued that the definition's inclusion of "automated clients" reintroduces concerns about internal system operations, which this category was meant to avoid. The definition should be limited to outputs presented to *human users* or software directly operated by them, clearly defining an "external boundary." Martin acknowledged the complexity of tracing obligations across administrative domains with cascading systems.
    *   **Conceptual Challenges**: Ecker presented hypotheticals (e.g., human-in-the-loop hyperparameter tuning; AI-generated source code never seen by humans) to illustrate fundamental conceptual problems with defining "AI Output" and identifying what constitutes "output" in complex systems.
    *   **Liability and Progress**: Roberta noted that autonomous AI systems with agents talking to each other raise liability concerns and clash with the idea of a human interface for preferences. She expressed worry about finding agreement among end-users, SEOs, and the AI industry.
    *   **Definition Confusion**: Alain Klem and Alyssa expressed significant confusion about the wording of the "AI Output" definition, particularly phrases like "outputs that are presented to human users and outputs da-da-da-da-da."
    *   **Purpose of Processing**: Ted Hardy reiterated the idea that preferences are often about the *purpose* of processing (e.g., price discrimination, substitutive work) rather than merely the use of AI tools. He referenced Bradley Silver's draft on "substitutive use" as a potential framework. Chairs noted this could lead to rechartering discussions.
    *   **Unintended Consequences**: Meredith Jacob and Lila Tretikov cautioned that defining preferences based on "substitutive use" could lead to unintended consequences, expanding "ownership" in ways not recognized elsewhere and potentially stifling competition and pro-social uses (e.g., accessibility tools).
    *   **Policy vs. Technical**: Victoria Noble stressed that balancing user benefits and publisher interests, especially concerning pro-social uses, is a policy/regulatory task beyond a technical standards body. She also highlighted the importance of Section 3.2 of the document, which addresses binding consequences and flexibility.
    *   **Training in Output**: Ecker cautioned against removing the paragraph about model training within AI Output without careful consideration, as it could unintentionally disallow other valid forms of training not covered by "foundation model training."

## Decisions and Action Items

*   **Decision**: The "Search" category will be unnested from "AI Output" in future draft revisions.
*   **Action Item**: The chairs will coordinate with Alyssa on developing a set of common *use cases* to test proposed definitions for clarity and applicability.
*   **Action Item**: Review the concepts and granularity proposed in Krishna's draft, incorporating relevant ideas as issues in the working group's repository for discussion.
*   **Action Item**: Revise the definition of "AI Output" to clarify the scope of "output" (e.g., "human users" vs. "automated clients") and address conceptual problems with internal vs. external system boundaries.
*   **Action Item**: Revisit the paragraph regarding model training within the AI Output definition, considering the unnesting of Search and potential unintended consequences on other forms of training.
*   **Action Item**: Continue to engage with the concept of "purpose of processing" as a driver for preferences, potentially revisiting Bradley Silver's draft on substitutive use.

## Next Steps

*   Discussions will continue on the working group mailing list.
*   The next meeting session on Wednesday will begin with a discussion of the "Automated Processing" term.