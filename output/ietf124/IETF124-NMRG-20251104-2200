# NMRG

## Summary

The second session of NMRG featured a rich set of presentations and discussions centered on Network Digital Twins (NDTs), Agentic AI, Large Language Models (LLMs) in network management, and authorization policy sharing. Presentations covered a visualization tool for NDTs, an NDT-based architecture for AI-driven operations, a data and agent-aware network framework for AI training, problem statements for agentic AI in network management, semantic routing for LLMs, an LLM-assisted human-in-the-loop management framework, and a model for distributed authorization policy sharing. The session concluded with a discussion on efficient data indexing for Yang push to message brokers and its relevance to NDT scalability. Recurring themes included the challenges of scalability, security (especially agent reliability and data privacy), and the need for standardized, semantic interoperability across various layers of an AI-driven network.

## Key Discussion Points

*   **Network Digital Twin Visualization (Felix):**
    *   Presented DixieWIS, a real-time, multi-vendor, fine-grained visualization tool for NDTs, utilizing GNMI data.
    *   Key features include link colorization, bandwidth overlay, and a "time machine" for recalling historical events with granular detail.
    *   Noted the use of traffic shaping to mitigate bandwidth constraints inherent in NDT virtualization, proportionally scaling traffic to preserve network characteristics.
    *   **Benefits:** Enhanced operator cognition for application traffic engineering, "what-if" analysis, stability testing, and policy validation.
    *   **Scalability Concerns:** Python deque for historical data (120 snapshots/60 seconds) does not scale well; proposed Apache Kafka and time-series databases for long-term storage and improved performance. Discussed integrating compression, deduplication, and flow data (e.g., sFlow), along with tagging/thresholds for event highlighting.
    *   **Discussion:**
        *   A participant raised concerns about the overall usability vs. complexity of NDTs, questioning if the advantages justify the data collection, processing, and resource overhead. Felix clarified that NDTs are often used to abstract *parts* or *characteristics* of a real network rather than a complete, full-fidelity replica.
        *   The traffic shaping approach was clarified as dynamic, scaling traffic to a suitable fraction of the NDT's maximum capable throughput (e.g., 7 Mbps on an 80 Mbps capable virtual device) while preserving network characteristics.

*   **NDT-based Architecture for AI-driven Network Operations (Sheng):**
    *   Introduced an architecture integrating NDTs with agentic AI to enable AI-driven network operations, highlighting a shift towards a proactive operational lifecycle.
    *   The core autonomous domain comprises Network Digital Twin, Network Agent (defined as LLM + plan + memory + tooling + action), and a Knowledge Base, forming a closed-loop system.
    *   Updates to the draft include sections on security, technology, clarification of knowledge and tooling relationships, AI agent characteristics, and collaboration between small and large AI models.
    *   **Next Steps:** Further exploration of agent use cases, interaction logic between agents, knowledge base, and tools, and enhancing agent security mechanisms.

*   **Data and Agent-Aware Training Network (DITN) (Hisham):**
    *   Proposed a framework for an "intelligent, multi-plane network" specifically designed to meet the unique demands of AI systems (training, inference, agentic interaction), as traditional networks are not suited for distributed data handling.
    *   **Key Components:**
        *   **MTRCE (Model Training and Root Compute Engine):** An intelligent entity that takes a model, identifies suitable distributed data using "data descriptors," plans training, and manages model distribution.
        *   **DRRT (Data and Reachability Topology):** Maps network information to data needs, enabling the selection of appropriate datasets.
    *   Presented experiments in continual learning using neural architecture search-inspired (NWT) and Fisher algorithms, utilizing mini-batches as initial data descriptors, showing improved performance over random data selection.
    *   **Research Questions:** Explored challenges in defining data descriptors (beyond revealing samples), generalizing MTRCE algorithms across different learning frameworks (e.g., federated learning, knowledge distillation), and building effective DRRTs.
    *   **Discussion:**
        *   A participant questioned the framework's integration with existing transport layer issues and how it addresses agent-related security concerns like hallucinations. Hisham clarified DITN as an overlay but requiring underlay integration for agent and data discovery. He also suggested that DITN's intelligent components could themselves be implemented as agents, leveraging agentic protocols.
        *   It was emphasized that data descriptors and data topology are priority areas, particularly for enabling data governance without revealing sensitive information, potentially attracting private datasets for training.

*   **Motivations and Problem Statement of Agent AI for Network Management (Yongshan):**
    *   Presented an early-stage draft aiming to identify if agentic AI is suitable for network management and what problems it addresses, rather than proposing solutions.
    *   Highlighted six problems with existing technologies: architectural bottlenecks due to centralization, absence of agent-to-agent (A2A) *semantic* interoperability, lack of dynamic trust, real-time data validity issues, regularity of IBN intent translator engines, and oversimplification of Automatic Service Agents (ASA).
    *   Defined five objectives for agentic AI in network management: autonomous operation, intelligent resource orchestration, predictive security, novel network service models, and autonomous fidelity/action awareness.
    *   **Discussion:**
        *   Semantic interoperability in A2A was clarified as going beyond syntactic compatibility to ensure shared understanding.
        *   Concerns about "who watches the watchman" regarding agent security (hallucinations, disobedience) were raised, with the presenter acknowledging it as a complex problem for security experts to address collaboratively.
        *   It was noted that many of the proposed objectives were general to automation and autonomous networking, suggesting that Agent AI might be viewed more as a *solution approach* to existing challenges rather than generating entirely *new objectives*.

*   **VLM Semantic Router for LLM Network Access (Huang Min):**
    *   Presented a two-part proposal for a "Semantic Router" to facilitate LLM access, addressing vendor lock-in, lack of standardization for LLM API metadata, security awareness, and performance/cost trade-offs.
    *   **Part 1 (Provider Side):** An analyzer/semantic router classifies LLM prompt content (e.g., category, security sensitivity, complexity) using an LLM itself. This classification is then encoded into standardized HTTP headers. Downstream providers or routing intermediaries use these headers for intelligent routing and model selection, optimizing for security, performance, and cost.
    *   **Part 2 (Application Side):** Focuses on negotiation between application providers and the gateway. Proposed "auto parameters" (e.g., `auto` for model, tools, reasoning mode) and application-facing extension headers. This aims for vendor neutrality and seamless upgrades by allowing the gateway to dynamically select the best LLM model and capabilities.
    *   **Discussion:**
        *   Significant security concerns were raised regarding the trust required for the semantic router (especially if it handles sensitive data like PII) and the susceptibility of HTTP headers to various types of injection attacks (both traditional and AI-specific prompt injections). The presenter acknowledged these concerns and indicated a willingness to revise the draft to incorporate more robust security considerations.
        *   It was suggested that locating the router more locally (e.g., at the enterprise edge as an egress gateway) could mitigate some injection risks and facilitate local policy decisions regarding data exposure.

*   **LLM-assisted Network Management with Human-in-the-Loop (LLM-HiL) (Ming Che):**
    *   Introduced a framework for LLM agents to assist network management while explicitly keeping human operators in the loop, recognizing that human participation will remain crucial even in highly autonomous networks.
    *   The framework comprises an enhanced telemetry model (injecting semantics), an LLM Agent Decision Model (for task execution and configuration generation with access control), and the Human Operator.
    *   **Updates:** Detailed discussions on task agent communication (Model-Connected Protocol for tool invocation via IPCP, and Agent-to-Agent protocol, treating humans as special agents) and a task agent lifecycle (creation, updates, deletion).
    *   An implementation in a simple network environment with four basic agents (intent understanding, policy/config generation, resource evaluation) using the LangGraph framework was mentioned.
    *   **Discussion:** Security issues related to A2A protocols were noted as an area for further discussion and inclusion in the draft.

*   **Model for Distributed Authorization Policy Sharing (Lucia):**
    *   Addressed the need for dynamic, context-aware authorization policies in distributed, automating systems due to the fragmentation of existing policy languages and tools.
    *   Proposed a unifying model using YAML as a canonical representation for policies, treating them "as code" to allow for fine granularity (even at the data level) and dynamic adaptation to context (topology, risk, request info).
    *   The framework aims to cover the entire policy lifecycle.
    *   Discussed requirements for distributed policy management: granularity, context awareness, token alignment, lifecycle control, and interoperability.
    *   Explored the transformation of operator "intents" into enforceable policy code, requiring a shared semantic layer (actor, action, context) and mechanisms for trustability in this translation.
    *   **Discussion:** Clarified the role of a Policy Administration Point (PAP) in validating YAML policy schemas, extracting policy code, and distributing it to Policy Decision Points (PDPs), which then make authorization decisions.

*   **Message Keying for Yang Push to Message Broker (Thomas):**
    *   Presented a third document (complementing existing NEMOP drafts on architecture and schema) focused on efficient data taxonomy and indexing for Yang push to message brokers, allowing SQL-like querying without direct network access.
    *   Detailed how Yang push subscription IDs (local) are mapped to network-significant schema IDs, enabling efficient data organization within message broker topics (using schema name + subscription type) and message keys for indexing.
    *   **Benefits:** Allows consumption of specific data subsets (e.g., IETF interfaces for certain nodes), topic compaction, and streamlined discovery via a stream catalog.
    *   **Questions for NMRG:**
        1.  Does this solution address the "large-scale challenge" of data acquisition and storage complexity in the NDT Architecture draft?
        2.  Should the NDT Architecture's data collection section be revised to include data mesh integration, with Yang push to message broker as a proposed solution for organizing and maintaining data?
    *   **Discussion:**
        *   A participant from the NDT architecture group indicated existing individual drafts on data collection methods and data generation/optimization using AI/LLM for complexity.
        *   It was acknowledged that while these address *collection*, the *integration, organization, and maintenance* of data within a big data context for NDTs still represents a "long way to go."
        *   The general sense was that the proposed solution offers a *possible* and *scalable* approach for data collection and indexing. It was suggested that the NDT Architecture document might benefit from focusing more on *requirements* for data handling, allowing such solutions to be evaluated against those needs. The NDT Architecture document is expected to have another last call, inviting further input.

## Decisions and Action Items

*   **NDT Architecture Draft:** All interested parties are encouraged to provide input during the upcoming last call for the NDT Architecture document, especially concerning the requirements for data integration, organization, and maintenance.

## Next Steps

*   **DixieWIS (Felix):**
    *   Replace Python deque with Kafka and a time-series database for improved scalability, performance, and longer historical data recall.
    *   Integrate compression and deduplication algorithms for efficient data storage.
    *   Augment interface data with flow data (e.g., sFlow) for deeper application traffic insights.
    *   Implement a tagging feature with thresholds/triggers for automatic highlighting of events of interest.
*   **NDT-based AI Operations (Sheng):**
    *   Continue developing use cases for network agents and their interaction logic with knowledge bases and tools.
    *   Enhance agent security mechanisms within the proposed architecture.
*   **DITN (Hisham):**
    *   Seek feedback and collaboration from the community on defining more advanced "data descriptors" and developing MTRCE algorithms, with priority on DRRT (Data and Reachability Topology) and data descriptors.
*   **Agent AI for Network Management (Yongshan):**
    *   Bring more implementation examples and practical use cases to future presentations.
    *   Refine the stated objectives to clearly distinguish between general automation goals and specific objectives derived from Agent AI.
*   **VLM Semantic Router (Huang Min):**
    *   Revise the draft to incorporate comprehensive security considerations, particularly regarding trust in the router and mitigating HTTP header/prompt injection attacks.
    *   Collaborate on addressing redundancy and failover mechanisms for gateway deployments.
*   **LLM-HiL (Ming Che):**
    *   Add more detailed discussion on security issues related to Agent-to-Agent (A2A) protocols within the draft.
    *   Release the code for the LangGraph-based multi-agent implementation.
*   **Distributed Authorization Policy Sharing (Lucia):**
    *   Solicit feedback on the requirements and scope of the proposed model.
    *   Explore integration with existing intent-based networking (IBN) efforts, including alignment with intent translation drafts and mechanisms for policy exchange.
    *   Provide references for the Policy Administration Point (PAP) concept in the draft.
*   **Message Keying for Yang Push (Thomas):**
    *   Review existing NMRG drafts on NDT data collection, generation, and optimization to identify potential alignment or complementary aspects.
    *   Advocate for the NDT Architecture document to focus more on abstract data handling *requirements*, against which various solutions (including Yang push to message broker) can be evaluated.